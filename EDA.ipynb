{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tue Feb  8 15:43:58 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   29C    P0    31W / 250W |   1834MiB / 12198MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   30C    P0    25W / 250W |      2MiB / 12198MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE...  Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   30C    P0    24W / 250W |      2MiB / 12198MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     15023      C   ...3/envs/pytorch/bin/python     1283MiB |\n",
      "|    0   N/A  N/A     37724      C   ...3/envs/pytorch/bin/python      549MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# import os, sys\n",
    "# dir2 = os.path.abspath('')\n",
    "# dir1 = os.path.dirname(dir2)\n",
    "# if not dir1 in sys.path: sys.path.append(dir1)\n",
    "    \n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Monai testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from monai.data import CacheDataset, ZipDataset, DataLoader, Dataset, decollate_batch\n",
    "from tqdm import tqdm\n",
    "import monai.transforms as tf\n",
    "\n",
    "\n",
    "train_transforms = tf.Compose([\n",
    "    tf.LoadImaged(reader=\"NibabelReader\", keys=['image', 'label']),\n",
    "#     tf.Transposed(keys=['image', 'label'], indices=(2, 0, 1)),\n",
    "    tf.AsDiscreted(keys=['label'], threshold_values=True),\n",
    "    tf.ToNumpyd(keys=['image', 'label']),\n",
    "    tf.NormalizeIntensityd(keys=['image'], channel_wise=True),\n",
    "    tf.ToTensord(keys=['image', 'label']),\n",
    "    # Augmentation here\n",
    "])\n",
    "\n",
    "# save_dir = \"/cluster/home/kimsa/data/BraTs2020/BraTS2020_training_data/content/data_monai\"\n",
    "root_dir = \"/cluster/projects/mcintoshgroup/BraTs2020/data_monai/\"\n",
    "\n",
    "num_train = 260  # 70%, 40300 slices (volume 1 ~ 260)\n",
    "num_valid = 40 # 10% 6200 slices (volume 261 ~ 300)\n",
    "num_test = 69 # 20% 10695 slices (volume 301 ~ 369)\n",
    "\n",
    "image_list = sorted(glob(os.path.join(root_dir, \"image\", \"*.nii.gz\")))\n",
    "label_list = sorted(glob(os.path.join(root_dir, \"label\", \"*.nii.gz\")))\n",
    "\n",
    "get_volume_name = lambda x: os.path.basename(x).split(\"_slice\")[0]\n",
    "sort_key = lambda x: int(x.split('_')[-1])\n",
    "image_sort_key = lambda x: int(os.path.basename(x).split(\"_slice_\")[-1].replace(\".nii.gz\", \"\"))\n",
    "unique_volumes = sorted(np.unique([get_volume_name(x) for x in image_list]), key=sort_key)\n",
    "\n",
    "train_subjects, valid_subjects, test_subjects = unique_volumes[:num_train], unique_volumes[num_train:num_train+num_valid], unique_volumes[num_train+num_valid:]\n",
    "data = list()\n",
    "columns = [\"Max\", \"Min\", \"Mean\", \"Std\"]\n",
    "\n",
    "target_subjects = test_subjects\n",
    "\n",
    "pbar = tqdm(total=len(target_subjects))\n",
    "\n",
    "total_stats = np.zeros((len(target_subjects), 4, 6))\n",
    "for target_sub_idx, target_subject in enumerate(target_subjects):\n",
    "    subject_image_list = sorted([x for x in image_list if target_subject == get_volume_name(x)], key=image_sort_key)\n",
    "    subject_volume = np.zeros((len(subject_image_list), 4, 240, 240))\n",
    "    for img_idx, image in enumerate(subject_image_list):\n",
    "        subject_volume[img_idx] = nib.load(image).get_fdata()\n",
    "        \n",
    "    true_max = subject_volume.max((0, 2, 3))\n",
    "    true_min = subject_volume.min((0, 2, 3))\n",
    "    true_mean = subject_volume.mean((0, 2, 3))\n",
    "    true_std = subject_volume.std((0, 2, 3))\n",
    "    nonzero_mean = np.nanmean(np.where(subject_volume == 0, np.nan, subject_volume), (0, 2, 3))\n",
    "    nonzero_std = np.nanstd(np.where(subject_volume == 0, np.nan, subject_volume), (0, 2, 3))\n",
    "    \n",
    "    data = [\n",
    "        np.expand_dims(true_max, 1),\n",
    "        np.expand_dims(true_min, 1),\n",
    "        np.expand_dims(true_mean, 1),\n",
    "        np.expand_dims(true_std, 1),\n",
    "        np.expand_dims(nonzero_mean, 1),\n",
    "        np.expand_dims(nonzero_std, 1),\n",
    "    ]\n",
    "    subject_stats = np.expand_dims(np.concatenate(data, 1), 0)\n",
    "    total_stats[target_sub_idx] = subject_stats\n",
    "    pbar.update(1)\n",
    "    # break\n",
    "\n",
    "# Stats\n",
    "total_mean = total_stats.mean(0)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Min-Max Stats"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "excel_save_path = \"./asset/min_max_stats_test.xlsx\"\n",
    "mod_names = [\"T1\", \"T1Gd\", \"T2\", \"T2-FLAIR\"]\n",
    "mod_columns = [\"Max\", \"Min\"]\n",
    "mod_dfs = []\n",
    "\n",
    "for mod_idx, mod_name in enumerate(mod_names):\n",
    "    mod_min_max = total_stats[:, mod_idx, :2]\n",
    "    \n",
    "    mod_df = pd.DataFrame(data=mod_min_max, index=target_subjects, columns=mod_columns)\n",
    "    mod_dfs.append(mod_df)\n",
    "\n",
    "with pd.ExcelWriter(excel_save_path) as writer:\n",
    "    for mod_idx, mod_name in enumerate(mod_names):\n",
    "        mod_dfs[mod_idx].to_excel(writer, sheet_name=mod_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean-Std Stats"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "mod_names = [\"T1\", \"T1Gd\", \"T2\", \"T2-FLAIR\"]\n",
    "stat_names = [\"Average_of_Max\", \"Average_of_Min\", \"True_Mean\", \"True_Std\", \"Non_zero_Mean\", \"Non_zero_Std\"]\n",
    "stat_df = pd.DataFrame(data=total_mean, columns=stat_names, index=mod_names)\n",
    "stat_df.to_excel(\"./asset/mean_std_stats.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data transformation from hdf5 to nifti image (For monai)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = \"/cluster/home/kimsa/data/BraTs2020/BraTS2020_training_data/content/data\"\n",
    "save_dir = \"/cluster/home/kimsa/data/BraTs2020/BraTS2020_training_data/content/data_monai\"\n",
    "# save_dir = \"/cluster/projects/mcintoshgroup/BraTs2020/data_monai\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(save_dir, \"image\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(save_dir, \"label\"), exist_ok=True)\n",
    "brats_files = glob(os.path.join(root_dir, \"*.h5\"))\n",
    "\n",
    "shape_outlier = list()\n",
    "status = dict()\n",
    "pbar = tqdm(total=len(brats_files))\n",
    "\n",
    "\n",
    "def save_nii(nii_arr, path):\n",
    "    img = nib.Nifti1Image(nii_arr, np.eye(4))\n",
    "    nib.save(img, path)\n",
    "    return os.path.exists(path)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Iterate through brats files\n",
    "    for file_idx, file in enumerate(brats_files):\n",
    "        h5_obj = h5py.File(file)\n",
    "        image_arr = h5_obj[\"image\"][()]\n",
    "        label_arr = h5_obj[\"mask\"][()]\n",
    "        \n",
    "        # Transpose original image\n",
    "        image_arr = np.transpose(image_arr, (2, 0, 1))\n",
    "        label_arr = np.transpose(label_arr, (2, 0, 1))\n",
    "        \n",
    "        file_name = os.path.basename(file).replace(\".h5\", \".nii.gz\")\n",
    "        img_save_path = os.path.join(save_dir, \"image\", file_name)\n",
    "        lbl_save_path = os.path.join(save_dir, \"label\", file_name)\n",
    "        \n",
    "        img_saved = save_nii(image_arr, img_save_path)\n",
    "        lbl_saved = save_nii(label_arr, lbl_save_path)\n",
    "\n",
    "        status[f'{file_name}'] = [img_saved, lbl_saved]\n",
    "            \n",
    "        if (image_arr.shape != (4, 240, 240)) or (label_arr.shape != (3, 240, 240)):\n",
    "            shape_outlier.append(dict(\n",
    "                name=os.path.basename(file),\n",
    "                image_shape=image_arr.shape,\n",
    "                label_shape=label_arr.shape\n",
    "            ))\n",
    "        pbar.update(1)\n",
    "\n",
    "    print(\"\\nShape Outlier\")\n",
    "    print(shape_outlier)\n",
    "\n",
    "    status_df = pd.DataFrame.from_dict(status).T\n",
    "    status_df.columns = [\"Image Saved\", \"Label Saved\"]\n",
    "    status_df.to_csv(\"./tmp/transform.csv\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                               | 0/57195 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                       | 3/57195 [00:00<34:47, 27.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                       | 6/57195 [00:00<34:07, 27.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                       | 9/57195 [00:00<35:32, 26.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Shape Outlier\n",
      "[]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                      | 11/57195 [00:19<35:31, 26.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('torch38': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "e896ead94fb6e349be3082ceffd07e0803bce1e37c6657b1f305a42fd48d5e70"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}